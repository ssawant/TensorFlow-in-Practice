{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C3W4_NLP_Reading_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDKZKT+yCaIz3VGhJ56Nr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssawant/TensorFlow-in-Practice/blob/main/C3W4_NLP_Reading_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYbulBauVKXl",
        "outputId": "32c90e32-c486-428e-f5f7-3b287824ead8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdxZoVkOaSYO",
        "outputId": "063f4df7-e74c-41eb-bcd9-07e59772ee69"
      },
      "source": [
        "file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print(f\"{len(text)}\")\n",
        "print(f\"{text[:250]}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd9YK73xbv4M",
        "outputId": "3340f02a-a487-45de-a70f-9b756cdf9233"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f\"{len(vocab)}\")\n",
        "# print(f\"{vocab}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO61K6OpcET_",
        "outputId": "01ef9a4d-543f-46b5-8973-05983b9a4a19"
      },
      "source": [
        "# creating a mapping for unique characters to indices\n",
        "char2indx = {u:i for i, u in enumerate(vocab)}\n",
        "indx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2indx[c] for c in text])\n",
        "# print(f\"{len(text_as_int)}\")\n",
        "print(f\"{char2indx['C']}\")\n",
        "print(f\"{text[:13]} ===> {text_as_int[:13]}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "First Citizen ===> [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeATeiBXhzba",
        "outputId": "4a146620-26a7-49d5-b203-dd0bc8f72a63"
      },
      "source": [
        "seq_length = 100\n",
        "example_per_epoch = len(text)\n",
        "\n",
        "# Creating training example/ traget\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(15):\n",
        "  # print(i.numpy())\n",
        "  print(indx2char[i.numpy()])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n",
            "z\n",
            "e\n",
            "n\n",
            ":\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ-_PDp9johx",
        "outputId": "cacf4e6e-85b3-4644-ad0e-7b0c77daa42f"
      },
      "source": [
        "sequence = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "print(sequence.take(13))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<TakeDataset shapes: (101,), types: tf.int64>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOErMiSDlYFF",
        "outputId": "c5c9a6ea-5b3b-4d1c-8466-34a30c4a58ec"
      },
      "source": [
        "# return two list with first and last char removed\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequence.map(split_input_target) # lambda function call\n",
        "\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(indx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(indx2char[target_example.numpy()])))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6k5g8Swmw6i"
      },
      "source": [
        "# Creating training batch\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_Y6kswhnKvN",
        "outputId": "c8dd5209-1810-4731-c93d-34194a722a3c"
      },
      "source": [
        "vocab_size = len(vocab) # 65\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[BATCH_SIZE, None]),\n",
        "  tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "  tf.keras.layers.Dense(vocab_size)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}